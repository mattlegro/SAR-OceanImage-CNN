{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll train a basic dense fully connected MLP as a baseline for our image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up some generators, since we won't be able to load all the images into memory, accessing the file structure built in the preprocessing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root_dir = 'E:\\LargeDatasets\\SAR-Ocean-Images\\GeoTIFF\\OrganisationForModel'\n",
    "train_dir = f'{image_root_dir}\\\\train'\n",
    "val_dir = f'{image_root_dir}\\\\val'\n",
    "test_dir = f'{image_root_dir}\\\\test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch size here I determined to be the largest amount of images I can fit in my computers memory at one time, since it feels very complicated to use a generator and pre-process the images in the way necessary for a basic MLP input layer (Turn pixel array into 1D array). Then, we take one iteration from the generator using next() and process this for input as train, val and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattl\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:179: UserWarning: Using \".tiff\" files with multiple bands will cause distortion. Please verify your output.\n",
      "  warnings.warn('Using \".tiff\" files with multiple bands '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3756 images belonging to 10 classes.\n",
      "Found 3756 images belonging to 10 classes.\n",
      "Found 30041 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_dir, \n",
    "        target_size=(540, 490), batch_size = 100) \n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_dir, \n",
    "        target_size=(540, 490), batch_size = 800)\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_dir, \n",
    "        target_size=(540, 490), batch_size=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing for MLP Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 8000\n",
      "Number of testing samples: 100\n",
      "Number of validation samples: 800\n",
      "train_images shape: (8000, 540, 490, 3)\n",
      "train_labels shape: (8000, 10)\n",
      "test_images shape: (100, 540, 490, 3)\n",
      "test_labels shape: (100, 10)\n",
      "val_images shape: (800, 540, 490, 3)\n",
      "val_labels shape: (800, 10)\n"
     ]
    }
   ],
   "source": [
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 793800)\n",
      "(100, 793800)\n",
      "(800, 793800)\n"
     ]
    }
   ],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (8000,1))\n",
    "test_y = np.reshape(test_labels[:,0], (100,1))\n",
    "val_y = np.reshape(val_labels[:,0], (800,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, even though in this result, we have achieved a really solid accuracy over very few epochs, I must note that the networks success is entirely dependent on the random initialization of wieghts in the network. Often, it does not converge, for an accuracy of zero. Other times it maintains a small accuracy anywhere between 0 and 15%. Only very infrequently does it properly start to recognize patterns in the images that are useful.. and only if I really max out the number of images it can look at by maxing out my computer's memory as I have done presently. The number of layers and number of nodes in each layer could be tested further to improve convergence and stability, however, since this network is a baseline for CNNs, I do not feel the need to press further as the achieved accuracy is beyond expectation by a large margin anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1000, activation='relu', input_shape=(793800,)))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80/80 [==============================] - 129s 2s/step - loss: 3.0474 - accuracy: 0.8508 - val_loss: 3.3168 - val_accuracy: 0.8550\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 119s 1s/step - loss: 3.1036 - accuracy: 0.8723 - val_loss: 3.3168 - val_accuracy: 0.8550\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 119s 1s/step - loss: 3.1036 - accuracy: 0.8723 - val_loss: 3.3168 - val_accuracy: 0.8550\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 117s 1s/step - loss: 3.1036 - accuracy: 0.8723 - val_loss: 3.3168 - val_accuracy: 0.8550\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 118s 1s/step - loss: 3.1036 - accuracy: 0.8723 - val_loss: 3.3168 - val_accuracy: 0.8550\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=5,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(val_img, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 106s 423ms/step - loss: 3.1036 - accuracy: 0.8723\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_img, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 178ms/step - loss: 3.6257 - accuracy: 0.8300\n"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(test_img, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhTElEQVR4nO3de5RU5Z3u8e9DoyCCqICIQmw0RtRjaLFDFI3BUSNeIjGDSwjjAM4s72M0x1GSMQmJ8SyPMaPjweiQEa84qPEykPESIYlmkhmlQS6Coi222oKIEAEvCC2/88fe3RZFdXdV23QB+/msxap9efeu3367qKf2W1W7FBGYmVn2dCp3AWZmVh4OADOzjHIAmJlllAPAzCyjHABmZhnlADAzyygHgDWR9ISkce3dtpwk1Uk6aRvsNyR9MZ2+XdIPi2nbhvsZK+m3ba3TrCXy9wB2bJI+yJntBnwCfJrOXxAR0zq+qu2HpDrg7yNiVjvvN4CDI6K2vdpKqgReB3aJiIZ2KdSsBZ3LXYB9PhHRvXG6pSc7SZ39pGLbCz8etw8eAtpJSRouqV7S1ZLeAe6UtJek30haJekv6XT/nG3+IOnv0+nxkv5L0o1p29clndrGtgMlPStpvaRZkm6VdF8zdRdT47WS/pTu77eSeuesP1fSG5JWS/qnFvrnaEnvSKrIWXaWpIXp9FBJ/y3pfUkrJE2WtGsz+7pL0s9y5v8x3Wa5pPPy2p4u6QVJ6yS9JWlSzupn09v3JX0g6ZjGvs3ZfpikOZLWprfDiu2bEvt5b0l3psfwF0mP5awbKWl+egyvSRqRLt9iuE3SpMa/s6TKdCjs7yS9CfwuXf5Q+ndYmz5GDs/ZfjdJv0j/nmvTx9hukv5T0j/kHc9CSd8qdKzWPAfAzm1fYG/gAOB8kr/3nen8F4CPgcktbP9VYCnQG7gBuEOS2tD2fuB5oBcwCTi3hfsspsbvABOAfYBdgSsBJB0G3Jbuf7/0/vpTQET8D/Ah8Fd5+70/nf4UuCI9nmOAE4GLW6ibtIYRaT0nAwcD+e8/fAj8LbAncDpwUc4T1/Hp7Z4R0T0i/jtv33sD/wnckh7bPwP/KalX3jFs1TcFtNbP95IMKR6e7uumtIahwD3AP6bHcDxQ18x9FPJ14FDglHT+CZJ+2geYB+QOWd4IHAUMI3kcXwVsBu4G/qaxkaTBwP7A4yXUYQAR4X87yT+S/4gnpdPDgY1A1xbaVwF/yZn/A8kQEsB4oDZnXTcggH1LaUvy5NIAdMtZfx9wX5HHVKjGa3LmLwaeTKd/BEzPWbd72gcnNbPvnwFT0+keJE/OBzTT9nLg0Zz5AL6YTt8F/Cydngpcn9PuS7ltC+z3ZuCmdLoybds5Z/144L/S6XOB5/O2/29gfGt9U0o/A/1Inmj3KtDuXxvrbenxl85Pavw75xzbgS3UsGfapidJQH0MDC7QrguwhuR9FUiC4pfb4v/Uzv7PZwA7t1URsaFxRlI3Sf+anlKvIxly2DN3GCTPO40TEfFROtm9xLb7AWtylgG81VzBRdb4Ts70Rzk17Ze774j4EFjd3H2RvNr/tqQuwLeBeRHxRlrHl9JhkXfSOv4PydlAa7aoAXgj7/i+Kun36dDLWuDCIvfbuO838pa9QfLqt1FzfbOFVvp5AMnf7C8FNh0AvFZkvYU09Y2kCknXp8NI6/jsTKJ3+q9rofuKiE+AB4G/kdQJGENyxmIlcgDs3PI/4vW/gUOAr0bEHnw25NDcsE57WAHsLalbzrIBLbT/PDWuyN13ep+9mmscEUtInkBPZcvhH0iGkl4meZW5B/CDttRAcgaU635gBjAgInoCt+fst7WP5C0nGbLJ9QXg7SLqytdSP79F8jfbs8B2bwEHNbPPD0nO/hrtW6BN7jF+BxhJMkzWk+QsobGG94ANLdzX3cBYkqG5jyJvuMyK4wDIlh4kp9Xvp+PJP97Wd5i+oq4BJknaVdIxwDe3UY2/Bs6QdFz6hu1Paf0xfj9wGckT4EN5dawDPpA0CLioyBoeBMZLOiwNoPz6e5C8ut6Qjqd/J2fdKpKhlwOb2ffjwJckfUdSZ0nnAIcBvymytvw6CvZzRKwgGZv/Zfpm8S6SGgPiDmCCpBMldZK0f9o/APOB0Wn7amBUETV8QnKW1o3kLKuxhs0kw2n/LGm/9GzhmPRsjfQJfzPwC/zqv80cANlyM7Abyaur/wGe7KD7HUvyRupqknH3B0j+4xdyM22sMSIWA5eQPKmvAP4C1Ley2b+TvF/yu4h4L2f5lSRPzuuBX6U1F1PDE+kx/A6oTW9zXQz8VNJ6kvcsHszZ9iPgOuBPSj59dHTevlcDZ5C8el9N8qboGXl1F+tmWu7nc4FNJGdB75K8B0JEPE/yJvNNwFrgGT47K/khySv2vwA/YcszqkLuITkDextYktaR60pgETCHZMz//7Llc9Y9wBEk7ylZG/iLYNbhJD0AvBwR2/wMxHZekv4WOD8ijit3LTsqnwHYNifpK5IOSocMRpCM+z5W5rJsB5YOr10MTCl3LTsyB4B1hH1JPqL4Acln2C+KiBfKWpHtsCSdQvJ+yUpaH2ayFngIyMwso3wGYGaWUTvUxeB69+4dlZWV5S7DzGyHMnfu3Pciok/+8h0qACorK6mpqSl3GWZmOxRJ+d8gBzwEZGaWWQ4AM7OMcgCYmWWUA8DMLKMcAGZmGeUAsC1MmwaVldCpU3I7LdM/Kd8691dp3F+l26Z9Vu5fpCnl31FHHRW27dx3X0S3bhHw2b9u3ZLltjX3V2ncX6Vrrz4DaqLAc+oOdSmI6urq8PcAtp3KSnijwKeFDzgA6uo6uprtn/urNO6v0rVXn0maGxHVWy13AFijTp2S1xj5JNi8uePr2d65v0rj/ipde/VZcwHg9wCsyRfyf7ywleVZ5/4qjfurdNu6zxwA1uS666Bbty2XdeuWLLetub9K4/4q3bbuMweANRk7FqZMScYXpeR2ypRkuW3N/VUa91fptnWf+T0AM7OdnN8DMDOzLTgAzMwyygFgZpZRDgAzs4xyAJiZZZQDwMwsoxwAZmYZ5QAwM8soB4CZWUY5AMzMMsoBYGaWUQ4AM7OMcgCYmWVUUQEgaYSkpZJqJU0ssL6npJmSFkhaLGlCuvwQSfNz/q2TdHm6bm9JT0t6Nb3dq12PzMzMWtRqAEiqAG4FTgUOA8ZIOiyv2SXAkogYDAwHfiFp14hYGhFVEVEFHAV8BDyabjMRmB0RBwOz03kzM+sgxZwBDAVqI2JZRGwEpgMj89oE0EOSgO7AGqAhr82JwGsR0fgTxyOBu9Ppu4FvlV6+mZm1VTEBsD/wVs58fbos12TgUGA5sAj4bkTk/2TxaODfc+b7RsQKgPR2n0J3Lul8STWSalatWlVEuWZmVoxiAkAFluX/jNgpwHxgP6AKmCxpj6YdSLsCZwIPlVpgREyJiOqIqO7Tp0+pm5uZWTOKCYB6YEDOfH+SV/q5JgCPRKIWeB0YlLP+VGBeRKzMWbZSUj+A9PbdUos3M7O2KyYA5gAHSxqYvpIfDczIa/MmyRg/kvoChwDLctaPYcvhH9J9jEunxwH/UVrpZmb2eXRurUFENEi6FHgKqACmRsRiSRem628HrgXukrSIZMjo6oh4D0BSN+Bk4IK8XV8PPCjp70gC5Ox2OiYzMyuCIvKH87df1dXVUVNTU+4yzMx2KJLmRkR1/nJ/E9jMLKMcAGZmGeUAMDPLKAeAmVlGOQDMzDLKAWBmllEOADOzjHIAmJlllAPAzCyjHABmZhnlADAzyygHgJlZRjkAzMwyygFgZpZRDgAzs4xyAJiZZZQDwMwsoxwAZmYZ5QAwM8soB4CZWUY5AMzMMsoBYGaWUQ4AM7OMcgCYmWWUA8DMLKMcAGZmGeUAMDPLKAeAmVlGOQDMzDLKAWBmllEOADOzjHIAmJlllAPAzCyjHABmZhnlADAzyygHgJlZRjkAzMwyqqgAkDRC0lJJtZImFljfU9JMSQskLZY0IWfdnpJ+LellSS9JOiZdPknS25Lmp/9Oa7/DMjOz1nRurYGkCuBW4GSgHpgjaUZELMlpdgmwJCK+KakPsFTStIjYCPwL8GREjJK0K9AtZ7ubIuLGdjsaMzMrWjFnAEOB2ohYlj6hTwdG5rUJoIckAd2BNUCDpD2A44E7ACJiY0S8317Fm5lZ2xUTAPsDb+XM16fLck0GDgWWA4uA70bEZuBAYBVwp6QXJP2bpN1ztrtU0kJJUyXtVejOJZ0vqUZSzapVq4o8LDMza00xAaACyyJv/hRgPrAfUAVMTl/9dwaGALdFxJHAh0Djewi3AQel7VcAvyh05xExJSKqI6K6T58+RZRrZmbFKCYA6oEBOfP9SV7p55oAPBKJWuB1YFC6bX1EPJe2+zVJIBARKyPi0/RM4VckQ01mZtZBigmAOcDBkgamb+KOBmbktXkTOBFAUl/gEGBZRLwDvCXpkLTdicCStF2/nO3PAl5s81GYmVnJWv0UUEQ0SLoUeAqoAKZGxGJJF6brbweuBe6StIhkyOjqiHgv3cU/ANPS8FhGcrYAcIOkKpLhpDrggnY7KjMza5Ui8ofzt1/V1dVRU1NT7jLMzHYokuZGRHX+cn8T2MwsoxwAZmYZ5QAwM8soB4CZWUY5AMzMMsoBYGaWUQ4AM7OMcgCYmWWUA8DMLKMcAGZmGeUAMDPLKAeAmVlGOQDMzDLKAWBmllEOADOzjHIAmJlllAPAzCyjHABmZhnlADAzyygHgJlZRjkAzMwyygFgZpZRDgAzs4xyAJiZZZQDwMwsoxwAZmYZ5QAwM8soB4CZWUY5AMzMMsoBYGaWUQ4AM7OMcgCYmWWUA8DMLKMcAGZmGeUAMDPLKAeAmVlGOQDMzDKqqACQNELSUkm1kiYWWN9T0kxJCyQtljQhZ92ekn4t6WVJL0k6Jl2+t6SnJb2a3u7VfodlZmataTUAJFUAtwKnAocBYyQdltfsEmBJRAwGhgO/kLRruu5fgCcjYhAwGHgpXT4RmB0RBwOz03kzM+sgxZwBDAVqI2JZRGwEpgMj89oE0EOSgO7AGqBB0h7A8cAdABGxMSLeT7cZCdydTt8NfOtzHIeZmZWomADYH3grZ74+XZZrMnAosBxYBHw3IjYDBwKrgDslvSDp3yTtnm7TNyJWAKS3+xS6c0nnS6qRVLNq1apij8vMzFpRTACowLLImz8FmA/sB1QBk9NX/52BIcBtEXEk8CElDvVExJSIqI6I6j59+pSyqZmZtaCYAKgHBuTM9yd5pZ9rAvBIJGqB14FB6bb1EfFc2u7XJIEAsFJSP4D09t22HYKZmbVFMQEwBzhY0sD0jd3RwIy8Nm8CJwJI6gscAiyLiHeAtyQdkrY7EViSTs8AxqXT44D/aPNRmJlZyTq31iAiGiRdCjwFVABTI2KxpAvT9bcD1wJ3SVpEMmR0dUS8l+7iH4BpaXgsIzlbALgeeFDS35EEyNnteFxmZtYKReQP52+/qquro6amptxlmJntUCTNjYjq/OX+JrCZWUY5AMzMMsoBYGaWUQ4AM7OMcgCYmWWUA8DMLKMcAGZmGeUAMDPLKAeAmVlGOQDMzDLKAWBmllEOADOzjHIAmJlllAPAzCyjHABmZhnlADAzyygHgJlZRjkAzMwyygFgZpZRDgAzs4xyAJiZZZQDwMwsoxwAZmYZ5QAwM8soB4CZWUY5AMzMMsoBYGaWUQ4AM7OMcgCYmWWUA8DMLKMcAGZmGeUAMDPLKAeAmVlGOQDMzDLKAWBmllEOADOzjHIAmJllVFEBIGmEpKWSaiVNLLC+p6SZkhZIWixpQs66OkmLJM2XVJOzfJKkt9Pl8yWd1j6HZGZmxejcWgNJFcCtwMlAPTBH0oyIWJLT7BJgSUR8U1IfYKmkaRGxMV1/QkS8V2D3N0XEjZ/zGMzMrA1aDQBgKFAbEcsAJE0HRgK5ARBAD0kCugNrgIZ2rrXNLr8c5s8vdxVmZm1XVQU339y++yxmCGh/4K2c+fp0Wa7JwKHAcmAR8N2I2JyuC+C3kuZKOj9vu0slLZQ0VdJehe5c0vmSaiTVrFq1qohyzcysGMWcAajAssibPwWYD/wVcBDwtKQ/RsQ64NiIWC5pn3T5yxHxLHAbcG26r2uBXwDnbXVHEVOAKQDV1dX591uU9k5NM7OdQTFnAPXAgJz5/iSv9HNNAB6JRC3wOjAIICKWp7fvAo+SDCkRESsj4tP0TOFXjcvNzKxjFBMAc4CDJQ2UtCswGpiR1+ZN4EQASX2BQ4BlknaX1CNdvjvwDeDFdL5fzvZnNS43M7OO0eoQUEQ0SLoUeAqoAKZGxGJJF6brbycZwrlL0iKSIaOrI+I9SQcCjybvDdMZuD8inkx3fYOkKpIhoDrggnY9MjMza5Ei2jSsXhbV1dVRU1PTekMzM2siaW5EVOcv9zeBzcwyygFgZpZRDgAzs4xyAJiZZZQDwMwso4r5JrCZGZs2baK+vp4NGzaUuxRrRteuXenfvz+77LJLUe0dAGZWlPr6enr06EFlZSXpd3tsOxIRrF69mvr6egYOHFjUNh4CMrOibNiwgV69evnJfzsliV69epV0huYAMLOi+cl/+1bq38cBYGaWUQ4AM9smpk2Dykro1Cm5nTbt8+1v9erVVFVVUVVVxb777sv+++/fNL9x48YWt62pqeGyyy5r9T6GDRv2+YrcwfhNYDNrd9Omwfnnw0cfJfNvvJHMA4wd27Z99urVi/npT/tNmjSJ7t27c+WVVzatb2hooHPnwk9p1dXVVFdvdSmcrfz5z39uW3E7KJ8BmFm7+6d/+uzJv9FHHyXL29P48eP53ve+xwknnMDVV1/N888/z7BhwzjyyCMZNmwYS5cuBeAPf/gDZ5xxBpCEx3nnncfw4cM58MADueWWW5r2171796b2w4cPZ9SoUQwaNIixY8fSeOHMxx9/nEGDBnHcccdx2WWXNe03V11dHV/72tcYMmQIQ4YM2SJYbrjhBo444ggGDx7MxIkTAaitreWkk05i8ODBDBkyhNdee619O6oZPgMws3b35pulLf88XnnlFWbNmkVFRQXr1q3j2WefpXPnzsyaNYsf/OAHPPzww1tt8/LLL/P73/+e9evXc8ghh3DRRRdt9dn5F154gcWLF7Pffvtx7LHH8qc//Ynq6mouuOACnn32WQYOHMiYMWMK1rTPPvvw9NNP07VrV1599VXGjBlDTU0NTzzxBI899hjPPfcc3bp1Y82aNQCMHTuWiRMnctZZZ7FhwwY2b95ccL/tzQFgZu3uC19Ihn0KLW9vZ599NhUVFQCsXbuWcePG8eqrryKJTZs2Fdzm9NNPp0uXLnTp0oV99tmHlStX0r9//y3aDB06tGlZVVUVdXV1dO/enQMPPLDpc/ZjxoxhypQpW+1/06ZNXHrppcyfP5+KigpeeeUVAGbNmsWECRPo1q0bAHvvvTfr16/n7bff5qyzzgKSL3N1FA8BmVm7u+46SJ/jmnTrlixvb7vvvnvT9A9/+ENOOOEEXnzxRWbOnNnsZ+K7dOnSNF1RUUFDQ0NRbYr9/ZSbbrqJvn37smDBAmpqaprepI6IrT6qWc7fZHEAmFm7GzsWpkyBAw4AKbmdMqXtbwAXa+3atey///4A3HXXXe2+/0GDBrFs2TLq6uoAeOCBB5qto1+/fnTq1Il7772XTz/9FIBvfOMbTJ06lY/SN0jWrFnDHnvsQf/+/XnssccA+OSTT5rWb2sOADPbJsaOhbo62Lw5ud3WT/4AV111Fd///vc59thjm55029Nuu+3GL3/5S0aMGMFxxx1H37596dmz51btLr74Yu6++26OPvpoXnnllaazlBEjRnDmmWdSXV1NVVUVN954IwD33nsvt9xyC1/+8pcZNmwY77zzTrvXXoh/EtLMivLSSy9x6KGHlruMsvvggw/o3r07EcEll1zCwQcfzBVXXFHuspoU+jv5JyHNzNrBr371K6qqqjj88MNZu3YtF1xwQblLajN/CsjMrARXXHHFdvWK//PwGYCZWUY5AMzMMsoBYGaWUQ4AM7OMcgCY2Q5h+PDhPPXUU1ssu/nmm7n44otb3Kbxo+OnnXYa77///lZtJk2a1PR5/OY89thjLFmypGn+Rz/6EbNmzSqh+u2TA8DMdghjxoxh+vTpWyybPn16sxdky/f444+z5557tum+8wPgpz/9KSeddFKb9rU98cdAzaxkl18O6aX5201VFdx8c/PrR40axTXXXMMnn3xCly5dqKurY/ny5Rx33HFcdNFFzJkzh48//phRo0bxk5/8ZKvtKysrqampoXfv3lx33XXcc889DBgwgD59+nDUUUcByWf8p0yZwsaNG/niF7/Ivffey/z585kxYwbPPPMMP/vZz3j44Ye59tprOeOMMxg1ahSzZ8/myiuvpKGhga985SvcdtttdOnShcrKSsaNG8fMmTPZtGkTDz30EIMGDdqiprq6Os4991w+/PBDACZPntz0ozQ33HAD9957L506deLUU0/l+uuvp7a2lgsvvJBVq1ZRUVHBQw89xEEHHdTmPvcZgJntEHr16sXQoUN58skngeTV/znnnIMkrrvuOmpqali4cCHPPPMMCxcubHY/c+fOZfr06bzwwgs88sgjzJkzp2ndt7/9bebMmcOCBQs49NBDueOOOxg2bBhnnnkmP//5z5k/f/4WT7gbNmxg/PjxPPDAAyxatIiGhgZuu+22pvW9e/dm3rx5XHTRRQWHmRovGz1v3jweeOCBpl8ty71s9IIFC7jqqquA5LLRl1xyCQsWLODPf/4z/fr1+1x96jMAMytZS6/Ut6XGYaCRI0cyffp0pk6dCsCDDz7IlClTaGhoYMWKFSxZsoQvf/nLBffxxz/+kbPOOqvpksxnnnlm07oXX3yRa665hvfff58PPviAU045pcV6li5dysCBA/nSl74EwLhx47j11lu5/PLLgSRQAI466igeeeSRrbYv92Wjd/ozgPb+XVIzK59vfetbzJ49m3nz5vHxxx8zZMgQXn/9dW688UZmz57NwoULOf3005u9DHSj/EsyNxo/fjyTJ09m0aJF/PjHP251P61dS63xktLNXXK63JeN3qkDoPF3Sd94AyI++11Sh4DZjql79+4MHz6c8847r+nN33Xr1rH77rvTs2dPVq5cyRNPPNHiPo4//ngeffRRPv74Y9avX8/MmTOb1q1fv55+/fqxadMmpuU8UfTo0YP169dvta9BgwZRV1dHbW0tkFzV8+tf/3rRx1Puy0bv1AHQUb9LamYdZ8yYMSxYsIDRo0cDMHjwYI488kgOP/xwzjvvPI499tgWtx8yZAjnnHMOVVVV/PVf/zVf+9rXmtZde+21fPWrX+Xkk0/e4g3b0aNH8/Of/5wjjzxyi9/r7dq1K3feeSdnn302RxxxBJ06deLCCy8s+ljKfdnonfpy0J06Ja/880nJNcrNrHi+HPSOwZeDTjX3+6Pb4ndJzcx2NDt1AHTk75Kame1oduoAKNfvkprtrHakIeMsKvXvU1QASBohaamkWkkTC6zvKWmmpAWSFkuakLOuTtIiSfMl1eQs31vS05JeTW/3KqnyIpXjd0nNdkZdu3Zl9erVDoHtVESwevXqkr4f0OoXwSRVALcCJwP1wBxJMyJiSU6zS4AlEfFNSX2ApZKmRcTGdP0JEfFe3q4nArMj4vo0VCYCVxdduZl1qP79+1NfX8+qVavKXYo1o2vXrvTv37/o9sV8E3goUBsRywAkTQdGArkBEEAPJd9c6A6sAbb+1sOWRgLD0+m7gT/gADDbbu2yyy4MHDiw3GVYOypmCGh/4K2c+fp0Wa7JwKHAcmAR8N2IaPygZQC/lTRX0vk52/SNiBUA6e0+he5c0vmSaiTV+JWHmVn7KSYACn1nOn8Q8BRgPrAfUAVMlrRHuu7YiBgCnApcIun4UgqMiCkRUR0R1X369CllUzMza0ExAVAPDMiZ70/ySj/XBOCRSNQCrwODACJieXr7LvAoyZASwEpJ/QDS23fbehBmZla6Yt4DmAMcLGkg8DYwGvhOXps3gROBP0rqCxwCLJO0O9ApItan098AfppuMwMYB1yf3v5Ha4XMnTv3PUlvFFFzIb2B/DeitweuqzSuqzSuqzTba13w+Wo7oNDCoi4FIek04GagApgaEddJuhAgIm6XtB9wF9CPZMjo+oi4T9KBJK/6IQmb+yPiunSfvYAHgS+QBMjZEbGmjQdXzDHUFPoqdLm5rtK4rtK4rtJsr3XBtqmtqN8DiIjHgcfzlt2eM72c5NV9/nbLgMHN7HM1yVmDmZmVwU79TWAzM2telgJgSrkLaIbrKo3rKo3rKs32Whdsg9p2qMtBm5lZ+8nSGYCZmeVwAJiZZdROFwBFXLlUkm5J1y+UNGQ7qWu4pLXpVVPnS/pRB9Q0VdK7kl5sZn25+qq1ujq8r9L7HSDp95JeSq96+90CbTq8z4qsqxyPr66Sns+5SvBPCrQpR38VU1dZHmPpfVdIekHSbwqsa9/+ioid5h/J9xReAw4EdgUWAIfltTkNeILk+wpHA89tJ3UNB37Twf11PDAEeLGZ9R3eV0XW1eF9ld5vP2BIOt0DeGU7eXwVU1c5Hl8CuqfTuwDPAUdvB/1VTF1leYyl9/094P5C99/e/bWznQE0Xbk0kktRN165NNdI4J5I/A+wZ+MlKcpcV4eLiGdJrtzanHL0VTF1lUVErIiIeen0euAltr4wYof3WZF1dbi0Dz5IZ3dJ/+V/6qQc/VVMXWUhqT9wOvBvzTRp1/7a2QKgmCuXFtOmHHUBHJOelj4h6fBtXFMxytFXxSprX0mqBI4kefWYq6x91kJdUIY+S4cz5pNc6+vpiNgu+quIuqA8j7GbgauAzc2sb9f+2tkCoJgrlxbTpr0Vc5/zgAMiYjDw/4DHtnFNxShHXxWjrH0lqTvwMHB5RKzLX11gkw7ps1bqKkufRcSnEVFFchHJoZL+V16TsvRXEXV1eH9JOgN4NyLmttSswLI299fOFgDFXLm0mDYdXldErGs8LY3k0hu7SOq9jetqTTn6qlXl7CtJu5A8yU6LiEcKNClLn7VWV7kfXxHxPsmPPo3IW1XWx1hzdZWpv44FzpRURzJM/FeS7str0679tbMFQNOVSyXtSnLl0hl5bWYAf5u+m340sDbSH6YpZ12S9pWkdHooyd9m9TauqzXl6KtWlauv0vu8A3gpIv65mWYd3mfF1FWOPpPUR9Ke6fRuwEnAy3nNytFfrdZVjv6KiO9HRP+IqCR5jvhdRPxNXrN27a+iLga3o4iIBkmXAk/x2ZVLFyvnyqUkF7U7DagFPiL5LYPtoa5RwEWSGoCPgdGRvu2/rUj6d5JPO/SWVA/8mOQNsbL1VZF1dXhfpY4FzgUWpePHAD8guaJtOfusmLrK0Wf9gLuV/K54J+DBiPhNuf8/FllXuR5jW9mW/eVLQZiZZdTONgRkZmZFcgCYmWWUA8DMLKMcAGZmGeUAMDPLKAeAmVlGOQDMzDLq/wNhB20jNkpIpAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Understanding of Saving and Reloading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('SavedModels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\SavedModels\\BaselineMLP\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('.\\SavedModels\\BaselineMLP', overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[793800,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-88cfa3fc0b14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.\\SavedModels\\BaselineMLP'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m       \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m   raise IOError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    118\u001b[0m   \u001b[1;31m# TODO(kathywu): Add code to load from objects that contain all endpoints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m   model = tf_load.load_internal(\n\u001b[0m\u001b[0;32m    121\u001b[0m       path, options=options, loader_cls=KerasObjectLoader)\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls)\u001b[0m\n\u001b[0;32m    630\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0m\u001b[0;32m    633\u001b[0m                             ckpt_options)\n\u001b[0;32m    634\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_models_to_reconstruct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasObjectLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# Now that the node object has been fully loaded, and the checkpoint has\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options)\u001b[0m\n\u001b[0;32m    128\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_functions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_WrapperFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcrete_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_load_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;31m# loaded from config may create variables / other objects during\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;31m# initialization. These are recorded in `_nodes_recreated_from_config`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layer_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[1;31m# Load all other nodes and functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_load_layers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m       \u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetric_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_load_layer\u001b[1;34m(self, proto, node_id)\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;31m# Detect whether this object can be revived from the config. If not, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[1;31m# revive from the SavedModel instead.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m     \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_revive_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m       \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrevive_custom_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_revive_from_config\u001b[1;34m(self, identifier, metadata, node_id)\u001b[0m\n\u001b[0;32m    357\u001b[0m       obj = (\n\u001b[0;32m    358\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_revive_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m           self._revive_layer_from_config(metadata, node_id))\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_revive_layer_from_config\u001b[1;34m(self, metadata, node_id)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[0mbuild_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'build_input_shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m     \u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_build_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_try_build_layer\u001b[1;34m(self, obj, node_id, build_input_shape)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbuild_input_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m       \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_input_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m       \u001b[0mbase_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1169\u001b[0m                        'should be defined. Found `None`.')\n\u001b[0;32m   1170\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1171\u001b[1;33m     self.kernel = self.add_weight(\n\u001b[0m\u001b[0;32m   1172\u001b[0m         \u001b[1;34m'kernel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlast_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[0mcaching_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m     variable = self._add_variable_with_custom_getter(\n\u001b[0m\u001b[0;32m    598\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheckpoint_initializer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m     new_variable = getter(\n\u001b[0m\u001b[0;32m    746\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    131\u001b[0m   \u001b[1;31m# can remove the V1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   \u001b[0mvariable_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m   return tf_variables.VariableV1(\n\u001b[0m\u001b[0;32m    134\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     return previous_getter(\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m                         shape=None):\n\u001b[0;32m    198\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2581\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2582\u001b[0m     \u001b[0mdistribute_strategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"distribute_strategy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2583\u001b[1;33m     return resource_variable_ops.ResourceVariable(\n\u001b[0m\u001b[0;32m   2584\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2585\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1505\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_proto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1506\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1507\u001b[1;33m       self._init_from_args(\n\u001b[0m\u001b[0;32m   1508\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1509\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1649\u001b[0m           \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initializer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[1;32m-> 1651\u001b[1;33m                 \u001b[0minitial_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1652\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[0;32m   1653\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype)\u001b[0m\n\u001b[0;32m    395\u001b[0m        \u001b[1;33m(\u001b[0m\u001b[0mvia\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_floatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \"\"\"\n\u001b[1;32m--> 397\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVarianceScaling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_get_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m   1041\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m       \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m     return op(\n\u001b[0m\u001b[0;32m   1044\u001b[0m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    305\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m     \u001b[1;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    337\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[793800,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]"
     ]
    }
   ],
   "source": [
    "test = models.load_model('.\\SavedModels\\BaselineMLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 187ms/step - loss: 3.6257 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.625703811645508, 1.0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.evaluate(test_img, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 230ms/step - loss: 3.6257 - accuracy: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.625703811645508, 0.8299999833106995]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_img, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I am getting a very strange result. Why do I all of a sudden get an accuracy of 1.0?? Let's do some comparisons based on suggestions in this [thread](https://github.com/keras-team/keras/issues/4875)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 1000)              793801000 \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 794,003,210\n",
      "Trainable params: 794,003,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 1000)              793801000 \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 794,003,210\n",
      "Trainable params: 794,003,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_6/kernel:0' shape=(793800, 1000) dtype=float32, numpy=\n",
       "array([[ 1.8054952e-03,  5.0448277e-04,  2.9764161e-04, ...,\n",
       "        -1.7655678e-03, -1.3915773e-03, -2.1946286e-03],\n",
       "       [ 2.0716309e-03,  9.8874676e-04,  1.6160856e-03, ...,\n",
       "        -2.6015539e-03, -1.2332891e-03,  1.7200515e-03],\n",
       "       [ 1.1351532e-03, -1.3860001e-03, -2.4173937e-03, ...,\n",
       "        -2.6394147e-04,  2.6250025e-05, -2.3957628e-03],\n",
       "       ...,\n",
       "       [ 2.2395765e-03, -4.9922313e-04, -8.8690722e-04, ...,\n",
       "         1.7798601e-03,  9.7904843e-04,  2.5542008e-03],\n",
       "       [-2.0869833e-03, -2.1965518e-03, -1.7638109e-03, ...,\n",
       "         7.1158865e-05,  1.5134567e-03,  2.0027247e-03],\n",
       "       [-1.6891693e-03,  1.7482748e-03, -2.3235867e-03, ...,\n",
       "        -5.3268927e-04, -2.5978175e-03,  3.7841359e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_6/kernel:0' shape=(793800, 1000) dtype=float32, numpy=\n",
       "array([[ 1.8054952e-03,  5.0448277e-04,  2.9764161e-04, ...,\n",
       "        -1.7655678e-03, -1.3915773e-03, -2.1946286e-03],\n",
       "       [ 2.0716309e-03,  9.8874676e-04,  1.6160856e-03, ...,\n",
       "        -2.6015539e-03, -1.2332891e-03,  1.7200515e-03],\n",
       "       [ 1.1351532e-03, -1.3860001e-03, -2.4173937e-03, ...,\n",
       "        -2.6394147e-04,  2.6250025e-05, -2.3957628e-03],\n",
       "       ...,\n",
       "       [ 2.2395765e-03, -4.9922313e-04, -8.8690722e-04, ...,\n",
       "         1.7798601e-03,  9.7904843e-04,  2.5542008e-03],\n",
       "       [-2.0869833e-03, -2.1965518e-03, -1.7638109e-03, ...,\n",
       "         7.1158865e-05,  1.5134567e-03,  2.0027247e-03],\n",
       "       [-1.6891693e-03,  1.7482748e-03, -2.3235867e-03, ...,\n",
       "        -5.3268927e-04, -2.5978175e-03,  3.7841359e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still reading from the thread.. most problems seem to be related to more complicated architectures... weights and architecture of our model seem to be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 171ms/step - loss: 3.6257 - accuracy: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.625703811645508, 0.8299999833106995]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.evaluate(test_img, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 91s 362ms/step - loss: 3.1036 - accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.103602409362793, 0.8722500205039978]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.evaluate(train_img, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! Finally, near the bottom of a 3 year plus old thread, I indirectly realized that I needed to recompile the loaded model. Why, I am not sure. But let's move on to the CNN notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
