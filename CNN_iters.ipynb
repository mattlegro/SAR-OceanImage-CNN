{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08112ba-528e-46d4-a14c-5e46329579e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8db8225-c422-4d1a-b50c-9d4a02a3bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root_dir = 'E:\\LargeDatasets\\SAR-Ocean-Images\\GeoTIFF\\OrganisationForModel'\n",
    "train_dir = f'{image_root_dir}\\\\train'\n",
    "val_dir = f'{image_root_dir}\\\\val'\n",
    "test_dir = f'{image_root_dir}\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec53353-ad25-40c3-9c42-2060c882f65c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30041 images belonging to 10 classes.\n",
      "Found 3756 images belonging to 10 classes.\n",
      "Found 3756 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_dir, class_mode = 'categorical', color_mode = 'grayscale',\n",
    "        target_size=(540, 490), batch_size= batch_size)\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "        val_dir, class_mode = 'categorical', color_mode = 'grayscale',\n",
    "        target_size=(540, 490), batch_size = batch_size)\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_dir, class_mode = 'categorical', color_mode = 'grayscale',\n",
    "        target_size=(540, 490), batch_size = batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a578d5f-4485-4804-b3d3-72e69bf172d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'E:\\LargeDatasets\\SAR-Ocean-Images\\GeoTIFF\\OrganisationForModel\\\\train\\H\\s1a-wv1-slc-vv-20160107t131721-20160107t131724-009388-00d975-029.tiff'\n",
    "test_image = load_img(image_path, target_size = (540,490))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926c6354-2905-4bcd-9079-1ee8d62f6671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22897c65-5b67-4e43-915d-333408e1c0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ 5208.],\n",
       "          [ 8006.],\n",
       "          [ 7369.],\n",
       "          ...,\n",
       "          [ 6709.],\n",
       "          [ 5769.],\n",
       "          [ 6162.]],\n",
       " \n",
       "         [[16062.],\n",
       "          [14882.],\n",
       "          [14418.],\n",
       "          ...,\n",
       "          [12528.],\n",
       "          [14049.],\n",
       "          [14126.]],\n",
       " \n",
       "         [[14554.],\n",
       "          [12043.],\n",
       "          [11189.],\n",
       "          ...,\n",
       "          [13178.],\n",
       "          [13861.],\n",
       "          [14161.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[12395.],\n",
       "          [17721.],\n",
       "          [15952.],\n",
       "          ...,\n",
       "          [13826.],\n",
       "          [13790.],\n",
       "          [12741.]],\n",
       " \n",
       "         [[13593.],\n",
       "          [14812.],\n",
       "          [14933.],\n",
       "          ...,\n",
       "          [11751.],\n",
       "          [13229.],\n",
       "          [13235.]],\n",
       " \n",
       "         [[ 4731.],\n",
       "          [ 4088.],\n",
       "          [ 3691.],\n",
       "          ...,\n",
       "          [ 4041.],\n",
       "          [ 3023.],\n",
       "          [ 4032.]]],\n",
       " \n",
       " \n",
       "        [[[ 7927.],\n",
       "          [ 6528.],\n",
       "          [ 7054.],\n",
       "          ...,\n",
       "          [ 7091.],\n",
       "          [ 6398.],\n",
       "          [ 7079.]],\n",
       " \n",
       "         [[15164.],\n",
       "          [15336.],\n",
       "          [15391.],\n",
       "          ...,\n",
       "          [16965.],\n",
       "          [14168.],\n",
       "          [13406.]],\n",
       " \n",
       "         [[15173.],\n",
       "          [17182.],\n",
       "          [15172.],\n",
       "          ...,\n",
       "          [17065.],\n",
       "          [14955.],\n",
       "          [16190.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[16913.],\n",
       "          [14657.],\n",
       "          [13037.],\n",
       "          ...,\n",
       "          [17392.],\n",
       "          [12340.],\n",
       "          [14231.]],\n",
       " \n",
       "         [[15712.],\n",
       "          [13085.],\n",
       "          [12300.],\n",
       "          ...,\n",
       "          [14593.],\n",
       "          [13117.],\n",
       "          [13142.]],\n",
       " \n",
       "         [[ 5298.],\n",
       "          [ 3799.],\n",
       "          [ 4265.],\n",
       "          ...,\n",
       "          [ 4327.],\n",
       "          [ 4506.],\n",
       "          [ 4128.]]],\n",
       " \n",
       " \n",
       "        [[[ 4985.],\n",
       "          [ 3060.],\n",
       "          [ 2873.],\n",
       "          ...,\n",
       "          [ 2431.],\n",
       "          [ 1475.],\n",
       "          [ 1268.]],\n",
       " \n",
       "         [[ 9171.],\n",
       "          [ 8479.],\n",
       "          [ 8719.],\n",
       "          ...,\n",
       "          [10275.],\n",
       "          [ 6896.],\n",
       "          [ 6995.]],\n",
       " \n",
       "         [[10574.],\n",
       "          [ 9418.],\n",
       "          [12744.],\n",
       "          ...,\n",
       "          [10174.],\n",
       "          [ 6913.],\n",
       "          [ 6416.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 5760.],\n",
       "          [ 5602.],\n",
       "          [ 5228.],\n",
       "          ...,\n",
       "          [10812.],\n",
       "          [ 9810.],\n",
       "          [ 8491.]],\n",
       " \n",
       "         [[ 4938.],\n",
       "          [ 5638.],\n",
       "          [ 4707.],\n",
       "          ...,\n",
       "          [ 8661.],\n",
       "          [ 8018.],\n",
       "          [ 7194.]],\n",
       " \n",
       "         [[ 3666.],\n",
       "          [ 3186.],\n",
       "          [ 3687.],\n",
       "          ...,\n",
       "          [ 6159.],\n",
       "          [ 4798.],\n",
       "          [ 5423.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 3891.],\n",
       "          [ 4402.],\n",
       "          [ 5282.],\n",
       "          ...,\n",
       "          [ 4083.],\n",
       "          [ 3913.],\n",
       "          [ 4008.]],\n",
       " \n",
       "         [[11803.],\n",
       "          [11098.],\n",
       "          [14351.],\n",
       "          ...,\n",
       "          [12811.],\n",
       "          [11312.],\n",
       "          [14328.]],\n",
       " \n",
       "         [[16042.],\n",
       "          [15603.],\n",
       "          [14183.],\n",
       "          ...,\n",
       "          [16224.],\n",
       "          [15519.],\n",
       "          [14283.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[15027.],\n",
       "          [16205.],\n",
       "          [14107.],\n",
       "          ...,\n",
       "          [13590.],\n",
       "          [14910.],\n",
       "          [14645.]],\n",
       " \n",
       "         [[15042.],\n",
       "          [18282.],\n",
       "          [13404.],\n",
       "          ...,\n",
       "          [12420.],\n",
       "          [14213.],\n",
       "          [14814.]],\n",
       " \n",
       "         [[ 9724.],\n",
       "          [ 9810.],\n",
       "          [ 8935.],\n",
       "          ...,\n",
       "          [ 9374.],\n",
       "          [ 8982.],\n",
       "          [ 7464.]]],\n",
       " \n",
       " \n",
       "        [[[ 5178.],\n",
       "          [ 6604.],\n",
       "          [ 7372.],\n",
       "          ...,\n",
       "          [ 4419.],\n",
       "          [ 5179.],\n",
       "          [ 5923.]],\n",
       " \n",
       "         [[16000.],\n",
       "          [16644.],\n",
       "          [19780.],\n",
       "          ...,\n",
       "          [10466.],\n",
       "          [11413.],\n",
       "          [20737.]],\n",
       " \n",
       "         [[20180.],\n",
       "          [14577.],\n",
       "          [23867.],\n",
       "          ...,\n",
       "          [10249.],\n",
       "          [ 9362.],\n",
       "          [17514.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[18103.],\n",
       "          [14418.],\n",
       "          [15929.],\n",
       "          ...,\n",
       "          [ 8032.],\n",
       "          [18321.],\n",
       "          [28002.]],\n",
       " \n",
       "         [[14888.],\n",
       "          [14893.],\n",
       "          [14022.],\n",
       "          ...,\n",
       "          [14074.],\n",
       "          [14318.],\n",
       "          [25056.]],\n",
       " \n",
       "         [[ 7203.],\n",
       "          [ 7285.],\n",
       "          [ 8516.],\n",
       "          ...,\n",
       "          [ 8586.],\n",
       "          [ 7853.],\n",
       "          [ 9806.]]],\n",
       " \n",
       " \n",
       "        [[[ 3965.],\n",
       "          [ 3542.],\n",
       "          [ 4299.],\n",
       "          ...,\n",
       "          [ 4420.],\n",
       "          [ 4363.],\n",
       "          [ 3823.]],\n",
       " \n",
       "         [[11573.],\n",
       "          [12505.],\n",
       "          [10200.],\n",
       "          ...,\n",
       "          [ 9879.],\n",
       "          [11156.],\n",
       "          [ 9729.]],\n",
       " \n",
       "         [[10955.],\n",
       "          [13305.],\n",
       "          [12286.],\n",
       "          ...,\n",
       "          [10220.],\n",
       "          [13252.],\n",
       "          [12113.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[12539.],\n",
       "          [12650.],\n",
       "          [14728.],\n",
       "          ...,\n",
       "          [16469.],\n",
       "          [13018.],\n",
       "          [13503.]],\n",
       " \n",
       "         [[11760.],\n",
       "          [15082.],\n",
       "          [12823.],\n",
       "          ...,\n",
       "          [12698.],\n",
       "          [ 9923.],\n",
       "          [12745.]],\n",
       " \n",
       "         [[ 3118.],\n",
       "          [ 4331.],\n",
       "          [ 3774.],\n",
       "          ...,\n",
       "          [ 3290.],\n",
       "          [ 3480.],\n",
       "          [ 3366.]]]], dtype=float32),\n",
       " array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc64fc47-8cdd-43c6-aba6-e25aadeaf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                        input_shape=(540, 490, 1)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1000, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b70944-dc1c-4d30-8d88-e0df56272c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23366316-77e8-414b-b11d-f012d6311bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 538, 488, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 536, 486, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 268, 243, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 266, 241, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 264, 239, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 132, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 130, 118, 256)     295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 116, 256)     590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 126, 114, 256)     590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 124, 112, 256)     590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 60, 54, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 58, 52, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 56, 50, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 54, 48, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 27, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 25, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 23, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 21, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 19, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 10, 8, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40960)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              40961000  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 61,186,442\n",
      "Trainable params: 61,186,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "349012a9-d1ee-40d3-9cf5-2f0dc8fad7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/3755 [..............................] - ETA: 13:04 - loss: 417.0409 - acc: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1317s vs `on_train_batch_end` time: 0.2862s). Check your callbacks.\n",
      "3755/3755 [==============================] - 1676s 446ms/step - loss: 1.9287 - acc: 0.4291 - val_loss: 1.0188 - val_acc: 0.6346\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                        steps_per_epoch= 30041//batch_size,\n",
    "                        epochs=1,\n",
    "                        validation_data=val_generator,\n",
    "                        validation_steps= 3756//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982c8cb2-f5d0-4219-b102-621407351d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                            input_shape=(540, 490, 3)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1000, activation='relu'))\n",
    "    model.add(layers.Dense(200, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7a1bd4-d0a4-42d8-93a0-a378d8bc6437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0828s vs `on_train_batch_end` time: 0.1825s). Check your callbacks.\n",
      "6008/6008 - 1742s - loss: 2.2701 - acc: 0.1257 - val_loss: 2.2293 - val_acc: 0.1305\n",
      "New best accuracy: 0.12571580708026886\n",
      "WARNING:tensorflow:From C:\\Users\\mattl\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\mattl\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0828s vs `on_train_batch_end` time: 0.1856s). Check your callbacks.\n",
      "6008/6008 - 1753s - loss: 2.2670 - acc: 0.1302 - val_loss: 2.2303 - val_acc: 0.1278\n",
      "New best accuracy: 0.13017712533473969\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0857s vs `on_train_batch_end` time: 0.1920s). Check your callbacks.\n",
      "6008/6008 - 1735s - loss: 2.2520 - acc: 0.1277 - val_loss: 2.2302 - val_acc: 0.1278\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0868s vs `on_train_batch_end` time: 0.1835s). Check your callbacks.\n",
      "6008/6008 - 1733s - loss: 2.2573 - acc: 0.1234 - val_loss: 2.2306 - val_acc: 0.1305\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0838s vs `on_train_batch_end` time: 0.1835s). Check your callbacks.\n",
      "6008/6008 - 1733s - loss: 2.2527 - acc: 0.1254 - val_loss: 2.2319 - val_acc: 0.1254\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0838s vs `on_train_batch_end` time: 0.1855s). Check your callbacks.\n",
      "6008/6008 - 1737s - loss: 2.2578 - acc: 0.1273 - val_loss: 2.2318 - val_acc: 0.1278\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1925s). Check your callbacks.\n",
      "6008/6008 - 1735s - loss: 2.2591 - acc: 0.1253 - val_loss: 2.2309 - val_acc: 0.1278\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1841s). Check your callbacks.\n",
      "6008/6008 - 1737s - loss: 2.2638 - acc: 0.1261 - val_loss: 2.2305 - val_acc: 0.1260\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0838s vs `on_train_batch_end` time: 0.1855s). Check your callbacks.\n",
      "6008/6008 - 1731s - loss: 2.2577 - acc: 0.1245 - val_loss: 2.2322 - val_acc: 0.1262\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1915s). Check your callbacks.\n",
      "6008/6008 - 1732s - loss: 2.2588 - acc: 0.1236 - val_loss: 2.2301 - val_acc: 0.1278\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0857s vs `on_train_batch_end` time: 0.1825s). Check your callbacks.\n",
      "6008/6008 - 1734s - loss: 2.2551 - acc: 0.1248 - val_loss: 2.2345 - val_acc: 0.1262\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0987s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n",
      "6008/6008 - 1731s - loss: 2.2516 - acc: 0.1232 - val_loss: 2.2322 - val_acc: 0.1262\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0857s vs `on_train_batch_end` time: 0.1825s). Check your callbacks.\n",
      "6008/6008 - 1741s - loss: 2.3049 - acc: 0.1242 - val_loss: 2.2304 - val_acc: 0.1276\n",
      "6008/6008 - 1730s - loss: 2.2640 - acc: 0.1241 - val_loss: 2.2324 - val_acc: 0.1254\n",
      "6008/6008 - 1739s - loss: 2.2580 - acc: 0.1262 - val_loss: 2.2301 - val_acc: 0.1262\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0858s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n",
      "6008/6008 - 1738s - loss: 2.2579 - acc: 0.1271 - val_loss: 2.2365 - val_acc: 0.1278\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n",
      "6008/6008 - 1737s - loss: 2.3018 - acc: 0.1274 - val_loss: 2.2322 - val_acc: 0.1254\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0853s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n",
      "6008/6008 - 1731s - loss: 2.2673 - acc: 0.1256 - val_loss: 2.2315 - val_acc: 0.1305\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0838s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n",
      "6008/6008 - 1737s - loss: 2.2550 - acc: 0.1276 - val_loss: 2.2334 - val_acc: 0.1302\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1835s). Check your callbacks.\n",
      "6008/6008 - 1740s - loss: 2.2531 - acc: 0.1227 - val_loss: 2.2309 - val_acc: 0.1262\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0837s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n",
      "6008/6008 - 1732s - loss: 2.2519 - acc: 0.1266 - val_loss: 2.2292 - val_acc: 0.1305\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1850s). Check your callbacks.\n",
      "6008/6008 - 1739s - loss: 2.2555 - acc: 0.1262 - val_loss: 2.2323 - val_acc: 0.1254\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0838s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-947484640661>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m               metrics=['acc'])\n\u001b[1;32m----> 7\u001b[1;33m     history = model.fit(train_generator,\n\u001b[0m\u001b[0;32m      8\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m30041\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \"\"\"\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    343\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m           \u001b[0mnumpy_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "for i in range(36):\n",
    "    model = instantiate_model()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=.0001),\n",
    "              metrics=['acc'])\n",
    "    history = model.fit(train_generator,\n",
    "                        steps_per_epoch= 30041//batch_size,\n",
    "                        epochs=1,\n",
    "                        validation_data=val_generator,\n",
    "                        validation_steps= 3756//batch_size,\n",
    "                        verbose = 2)\n",
    "    acc = history.history['acc'][-1]\n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        print(f'New best accuracy: {best_acc}')\n",
    "        model.save('.\\SavedModels\\iterCNN', overwrite = True)\n",
    "    del model\n",
    "    del history\n",
    "    tf.keras.backend.clear_session()\n",
    "    for i in range (100):\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf08fa-b36c-4b7c-b64c-c668dde8597f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
