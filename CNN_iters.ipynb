{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e08112ba-528e-46d4-a14c-5e46329579e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8db8225-c422-4d1a-b50c-9d4a02a3bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root_dir = 'E:\\LargeDatasets\\SAR-Ocean-Images\\GeoTIFF\\OrganisationForModel'\n",
    "train_dir = f'{image_root_dir}\\\\train'\n",
    "val_dir = f'{image_root_dir}\\\\val'\n",
    "test_dir = f'{image_root_dir}\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ec53353-ad25-40c3-9c42-2060c882f65c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30041 images belonging to 10 classes.\n",
      "Found 3756 images belonging to 10 classes.\n",
      "Found 3756 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_dir, class_mode = 'categorical', color_mode = 'grayscale',\n",
    "        target_size=(540, 490), batch_size= batch_size)\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "        val_dir, class_mode = 'categorical', color_mode = 'grayscale',\n",
    "        target_size=(540, 490), batch_size = batch_size)\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_dir, class_mode = 'categorical', color_mode = 'grayscale',\n",
    "        target_size=(540, 490), batch_size = batch_size, shuffle = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a578d5f-4485-4804-b3d3-72e69bf172d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'E:\\LargeDatasets\\SAR-Ocean-Images\\GeoTIFF\\OrganisationForModel\\\\train\\H\\s1a-wv1-slc-vv-20160107t131721-20160107t131724-009388-00d975-029.tiff'\n",
    "test_image = load_img(image_path, target_size = (540,490))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926c6354-2905-4bcd-9079-1ee8d62f6671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22897c65-5b67-4e43-915d-333408e1c0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ 1768.],\n",
       "          [ 1312.],\n",
       "          [ 1548.],\n",
       "          ...,\n",
       "          [ 1449.],\n",
       "          [ 2380.],\n",
       "          [ 2262.]],\n",
       " \n",
       "         [[ 6460.],\n",
       "          [ 6486.],\n",
       "          [ 5895.],\n",
       "          ...,\n",
       "          [ 5896.],\n",
       "          [ 5949.],\n",
       "          [ 6673.]],\n",
       " \n",
       "         [[ 5505.],\n",
       "          [ 5609.],\n",
       "          [ 5209.],\n",
       "          ...,\n",
       "          [ 4021.],\n",
       "          [ 5255.],\n",
       "          [ 6507.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 5963.],\n",
       "          [ 5678.],\n",
       "          [10339.],\n",
       "          ...,\n",
       "          [ 7489.],\n",
       "          [ 6817.],\n",
       "          [ 9932.]],\n",
       " \n",
       "         [[ 5418.],\n",
       "          [ 9668.],\n",
       "          [ 9097.],\n",
       "          ...,\n",
       "          [ 8454.],\n",
       "          [ 7058.],\n",
       "          [ 6848.]],\n",
       " \n",
       "         [[ 6423.],\n",
       "          [ 7258.],\n",
       "          [ 6422.],\n",
       "          ...,\n",
       "          [ 6535.],\n",
       "          [ 5325.],\n",
       "          [ 6115.]]],\n",
       " \n",
       " \n",
       "        [[[ 4020.],\n",
       "          [ 4623.],\n",
       "          [ 3930.],\n",
       "          ...,\n",
       "          [ 4572.],\n",
       "          [ 4174.],\n",
       "          [ 4441.]],\n",
       " \n",
       "         [[13624.],\n",
       "          [14289.],\n",
       "          [11712.],\n",
       "          ...,\n",
       "          [14278.],\n",
       "          [12851.],\n",
       "          [14700.]],\n",
       " \n",
       "         [[18584.],\n",
       "          [16749.],\n",
       "          [13815.],\n",
       "          ...,\n",
       "          [19243.],\n",
       "          [16020.],\n",
       "          [15098.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[16231.],\n",
       "          [13162.],\n",
       "          [13660.],\n",
       "          ...,\n",
       "          [15623.],\n",
       "          [17201.],\n",
       "          [17230.]],\n",
       " \n",
       "         [[11871.],\n",
       "          [10656.],\n",
       "          [12220.],\n",
       "          ...,\n",
       "          [14747.],\n",
       "          [14849.],\n",
       "          [13046.]],\n",
       " \n",
       "         [[ 3463.],\n",
       "          [ 3284.],\n",
       "          [ 4312.],\n",
       "          ...,\n",
       "          [ 4821.],\n",
       "          [ 4157.],\n",
       "          [ 3986.]]],\n",
       " \n",
       " \n",
       "        [[[ 8407.],\n",
       "          [ 9077.],\n",
       "          [11302.],\n",
       "          ...,\n",
       "          [ 8791.],\n",
       "          [ 8199.],\n",
       "          [ 7926.]],\n",
       " \n",
       "         [[25922.],\n",
       "          [23952.],\n",
       "          [24159.],\n",
       "          ...,\n",
       "          [25081.],\n",
       "          [19344.],\n",
       "          [22059.]],\n",
       " \n",
       "         [[27055.],\n",
       "          [29217.],\n",
       "          [27819.],\n",
       "          ...,\n",
       "          [23878.],\n",
       "          [21103.],\n",
       "          [24593.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[24542.],\n",
       "          [24912.],\n",
       "          [24821.],\n",
       "          ...,\n",
       "          [25662.],\n",
       "          [23408.],\n",
       "          [30361.]],\n",
       " \n",
       "         [[22344.],\n",
       "          [18593.],\n",
       "          [18286.],\n",
       "          ...,\n",
       "          [21896.],\n",
       "          [18555.],\n",
       "          [26148.]],\n",
       " \n",
       "         [[ 5338.],\n",
       "          [ 4580.],\n",
       "          [ 5813.],\n",
       "          ...,\n",
       "          [ 6513.],\n",
       "          [ 5211.],\n",
       "          [ 7013.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[10056.],\n",
       "          [ 9384.],\n",
       "          [ 9255.],\n",
       "          ...,\n",
       "          [ 7920.],\n",
       "          [ 7364.],\n",
       "          [ 7891.]],\n",
       " \n",
       "         [[16558.],\n",
       "          [16404.],\n",
       "          [17269.],\n",
       "          ...,\n",
       "          [16410.],\n",
       "          [16909.],\n",
       "          [16855.]],\n",
       " \n",
       "         [[18417.],\n",
       "          [18088.],\n",
       "          [18230.],\n",
       "          ...,\n",
       "          [17215.],\n",
       "          [16726.],\n",
       "          [16271.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[20155.],\n",
       "          [14352.],\n",
       "          [15002.],\n",
       "          ...,\n",
       "          [17305.],\n",
       "          [16228.],\n",
       "          [12719.]],\n",
       " \n",
       "         [[17032.],\n",
       "          [13068.],\n",
       "          [13280.],\n",
       "          ...,\n",
       "          [14878.],\n",
       "          [15945.],\n",
       "          [13765.]],\n",
       " \n",
       "         [[ 5137.],\n",
       "          [ 4535.],\n",
       "          [ 3973.],\n",
       "          ...,\n",
       "          [ 4084.],\n",
       "          [ 4757.],\n",
       "          [ 4725.]]],\n",
       " \n",
       " \n",
       "        [[[ 9444.],\n",
       "          [16419.],\n",
       "          [14648.],\n",
       "          ...,\n",
       "          [16528.],\n",
       "          [18233.],\n",
       "          [13336.]],\n",
       " \n",
       "         [[19777.],\n",
       "          [35426.],\n",
       "          [33150.],\n",
       "          ...,\n",
       "          [33419.],\n",
       "          [45800.],\n",
       "          [30942.]],\n",
       " \n",
       "         [[23709.],\n",
       "          [37454.],\n",
       "          [30657.],\n",
       "          ...,\n",
       "          [34743.],\n",
       "          [29365.],\n",
       "          [30516.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[32278.],\n",
       "          [24744.],\n",
       "          [22091.],\n",
       "          ...,\n",
       "          [31674.],\n",
       "          [28814.],\n",
       "          [30118.]],\n",
       " \n",
       "         [[26185.],\n",
       "          [23619.],\n",
       "          [27530.],\n",
       "          ...,\n",
       "          [32768.],\n",
       "          [25165.],\n",
       "          [27823.]],\n",
       " \n",
       "         [[ 8588.],\n",
       "          [ 6252.],\n",
       "          [ 7030.],\n",
       "          ...,\n",
       "          [ 8413.],\n",
       "          [ 8809.],\n",
       "          [ 8959.]]],\n",
       " \n",
       " \n",
       "        [[[ 5856.],\n",
       "          [ 5769.],\n",
       "          [ 5196.],\n",
       "          ...,\n",
       "          [ 6659.],\n",
       "          [ 6695.],\n",
       "          [ 5437.]],\n",
       " \n",
       "         [[19637.],\n",
       "          [19980.],\n",
       "          [16428.],\n",
       "          ...,\n",
       "          [22974.],\n",
       "          [17926.],\n",
       "          [15280.]],\n",
       " \n",
       "         [[21190.],\n",
       "          [25428.],\n",
       "          [20949.],\n",
       "          ...,\n",
       "          [27035.],\n",
       "          [22817.],\n",
       "          [18264.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[21547.],\n",
       "          [23499.],\n",
       "          [22359.],\n",
       "          ...,\n",
       "          [21845.],\n",
       "          [19811.],\n",
       "          [22276.]],\n",
       " \n",
       "         [[22831.],\n",
       "          [20653.],\n",
       "          [20866.],\n",
       "          ...,\n",
       "          [18780.],\n",
       "          [20305.],\n",
       "          [26154.]],\n",
       " \n",
       "         [[14618.],\n",
       "          [12531.],\n",
       "          [14082.],\n",
       "          ...,\n",
       "          [14491.],\n",
       "          [14997.],\n",
       "          [15592.]]]], dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc64fc47-8cdd-43c6-aba6-e25aadeaf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Sequential()\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu',\n",
    "#                         input_shape=(540, 490, 1)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(1000, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model = models.load_model('.\\SavedModels\\iterCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b70944-dc1c-4d30-8d88-e0df56272c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(learning_rate=.0001),\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23366316-77e8-414b-b11d-f012d6311bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 538, 488, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 536, 486, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 268, 243, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 266, 241, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 264, 239, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 132, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 130, 118, 256)     295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 116, 256)     590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 126, 114, 256)     590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 124, 112, 256)     590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 60, 54, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 58, 52, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 56, 50, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 54, 48, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 27, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 25, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 23, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 21, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 19, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 10, 8, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40960)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              40961000  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 61,186,442\n",
      "Trainable params: 61,186,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a86f086-29ef-41c6-b22d-f3ca3d4dd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='.\\SavedModels\\iterCNN',\n",
    "        save_best_only=True,\n",
    "        monitor=\"loss\",\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='loss', \n",
    "        factor=0.1, \n",
    "        patience=3,\n",
    "        min_delta=.01,\n",
    "        cooldown = 3\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    min_delta=.01,\n",
    "    patience=8,\n",
    "    restore_best_weights=True\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349012a9-d1ee-40d3-9cf5-2f0dc8fad7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "   2/3755 [..............................] - ETA: 12:23 - loss: 0.2655 - categorical_accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1317s vs `on_train_batch_end` time: 0.2653s). Check your callbacks.\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.5797 - categorical_accuracy: 0.8026\n",
      "Epoch 00001: loss improved from inf to 0.57967, saving model to .\\SavedModels\\iterCNN\n",
      "WARNING:tensorflow:From C:\\Users\\mattl\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\mattl\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1637s 436ms/step - loss: 0.5797 - categorical_accuracy: 0.8026 - val_loss: 0.6167 - val_categorical_accuracy: 0.7900\n",
      "Epoch 2/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.5120 - categorical_accuracy: 0.8249\n",
      "Epoch 00002: loss improved from 0.57967 to 0.51196, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1636s 436ms/step - loss: 0.5120 - categorical_accuracy: 0.8249 - val_loss: 0.6499 - val_categorical_accuracy: 0.7772\n",
      "Epoch 3/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.4513 - categorical_accuracy: 0.8475\n",
      "Epoch 00003: loss improved from 0.51196 to 0.45132, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1644s 438ms/step - loss: 0.4513 - categorical_accuracy: 0.8475 - val_loss: 0.4909 - val_categorical_accuracy: 0.8404\n",
      "Epoch 4/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.4202 - categorical_accuracy: 0.8573\n",
      "Epoch 00004: loss improved from 0.45132 to 0.42021, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1644s 438ms/step - loss: 0.4202 - categorical_accuracy: 0.8573 - val_loss: 0.4685 - val_categorical_accuracy: 0.8542\n",
      "Epoch 5/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.3664 - categorical_accuracy: 0.8733\n",
      "Epoch 00005: loss improved from 0.42021 to 0.36642, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1662s 443ms/step - loss: 0.3664 - categorical_accuracy: 0.8733 - val_loss: 0.6075 - val_categorical_accuracy: 0.8121\n",
      "Epoch 6/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.3295 - categorical_accuracy: 0.8865\n",
      "Epoch 00006: loss improved from 0.36642 to 0.32953, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1646s 438ms/step - loss: 0.3295 - categorical_accuracy: 0.8865 - val_loss: 0.4793 - val_categorical_accuracy: 0.8475\n",
      "Epoch 7/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.3036 - categorical_accuracy: 0.8974\n",
      "Epoch 00007: loss improved from 0.32953 to 0.30363, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1654s 440ms/step - loss: 0.3036 - categorical_accuracy: 0.8974 - val_loss: 0.5480 - val_categorical_accuracy: 0.8412\n",
      "Epoch 8/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.2658 - categorical_accuracy: 0.9096\n",
      "Epoch 00008: loss improved from 0.30363 to 0.26578, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1649s 439ms/step - loss: 0.2658 - categorical_accuracy: 0.9096 - val_loss: 0.4891 - val_categorical_accuracy: 0.8622\n",
      "Epoch 9/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.2337 - categorical_accuracy: 0.9199\n",
      "Epoch 00009: loss improved from 0.26578 to 0.23373, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1644s 438ms/step - loss: 0.2337 - categorical_accuracy: 0.9199 - val_loss: 0.5276 - val_categorical_accuracy: 0.8630\n",
      "Epoch 10/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.2098 - categorical_accuracy: 0.9290\n",
      "Epoch 00010: loss improved from 0.23373 to 0.20977, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1652s 440ms/step - loss: 0.2098 - categorical_accuracy: 0.9290 - val_loss: 0.5318 - val_categorical_accuracy: 0.8590\n",
      "Epoch 11/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.1934 - categorical_accuracy: 0.9360\n",
      "Epoch 00011: loss improved from 0.20977 to 0.19341, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1645s 438ms/step - loss: 0.1934 - categorical_accuracy: 0.9360 - val_loss: 0.4886 - val_categorical_accuracy: 0.8686\n",
      "Epoch 12/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.1826 - categorical_accuracy: 0.9421\n",
      "Epoch 00012: loss improved from 0.19341 to 0.18256, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1652s 440ms/step - loss: 0.1826 - categorical_accuracy: 0.9421 - val_loss: 0.5440 - val_categorical_accuracy: 0.8590\n",
      "Epoch 13/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.1676 - categorical_accuracy: 0.9452\n",
      "Epoch 00013: loss improved from 0.18256 to 0.16761, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1648s 439ms/step - loss: 0.1676 - categorical_accuracy: 0.9452 - val_loss: 0.5753 - val_categorical_accuracy: 0.8673\n",
      "Epoch 14/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.1506 - categorical_accuracy: 0.9526\n",
      "Epoch 00014: loss improved from 0.16761 to 0.15064, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1658s 442ms/step - loss: 0.1506 - categorical_accuracy: 0.9526 - val_loss: 0.5484 - val_categorical_accuracy: 0.8662\n",
      "Epoch 15/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.1316 - categorical_accuracy: 0.9585\n",
      "Epoch 00015: loss improved from 0.15064 to 0.13159, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1651s 440ms/step - loss: 0.1316 - categorical_accuracy: 0.9585 - val_loss: 0.6182 - val_categorical_accuracy: 0.8561\n",
      "Epoch 16/16\n",
      "3755/3755 [==============================] - ETA: 0s - loss: 0.1165 - categorical_accuracy: 0.9628\n",
      "Epoch 00016: loss improved from 0.13159 to 0.11653, saving model to .\\SavedModels\\iterCNN\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "3755/3755 [==============================] - 1653s 440ms/step - loss: 0.1165 - categorical_accuracy: 0.9628 - val_loss: 0.6519 - val_categorical_accuracy: 0.8483\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                        steps_per_epoch= 30041//batch_size,\n",
    "                        epochs=16,\n",
    "                        validation_data=val_generator,\n",
    "                        validation_steps= 3756//batch_size,\n",
    "                        callbacks = callbacks\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9cdc82e-bf16-4dd6-8814-4bc1505fd408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5796748399734497,\n",
       "  0.5119628310203552,\n",
       "  0.45132118463516235,\n",
       "  0.42021360993385315,\n",
       "  0.3664175271987915,\n",
       "  0.3295261263847351,\n",
       "  0.3036345839500427,\n",
       "  0.2657826244831085,\n",
       "  0.2337251454591751,\n",
       "  0.20977185666561127,\n",
       "  0.19340920448303223,\n",
       "  0.18255536258220673,\n",
       "  0.16760879755020142,\n",
       "  0.1506403237581253,\n",
       "  0.1315905600786209,\n",
       "  0.11652768403291702],\n",
       " 'categorical_accuracy': [0.8026171326637268,\n",
       "  0.8248926401138306,\n",
       "  0.8475343585014343,\n",
       "  0.8572570085525513,\n",
       "  0.8733060359954834,\n",
       "  0.8864915370941162,\n",
       "  0.8973795771598816,\n",
       "  0.9095994234085083,\n",
       "  0.9198548197746277,\n",
       "  0.9290114045143127,\n",
       "  0.936037003993988,\n",
       "  0.9420637488365173,\n",
       "  0.9451603293418884,\n",
       "  0.9525855183601379,\n",
       "  0.9584789872169495,\n",
       "  0.9627742767333984],\n",
       " 'val_loss': [0.6167066097259521,\n",
       "  0.6498900055885315,\n",
       "  0.4908738136291504,\n",
       "  0.46852558851242065,\n",
       "  0.6075376272201538,\n",
       "  0.47934991121292114,\n",
       "  0.5480213761329651,\n",
       "  0.489112913608551,\n",
       "  0.5276487469673157,\n",
       "  0.5318435430526733,\n",
       "  0.48858779668807983,\n",
       "  0.5439572334289551,\n",
       "  0.5753172636032104,\n",
       "  0.5484476685523987,\n",
       "  0.6182177662849426,\n",
       "  0.6519307494163513],\n",
       " 'val_categorical_accuracy': [0.7899786829948425,\n",
       "  0.7771854996681213,\n",
       "  0.8403518199920654,\n",
       "  0.8542110919952393,\n",
       "  0.8121002316474915,\n",
       "  0.8475479483604431,\n",
       "  0.8411513566970825,\n",
       "  0.8622068166732788,\n",
       "  0.8630064129829407,\n",
       "  0.8590085506439209,\n",
       "  0.8686034083366394,\n",
       "  0.8590085506439209,\n",
       "  0.8672707676887512,\n",
       "  0.8662046790122986,\n",
       "  0.8560767769813538,\n",
       "  0.848347544670105],\n",
       " 'lr': [1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04,\n",
       "  1e-04]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f31e14-9f6c-4322-9972-5751e5a81809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "871d180e-d5af-40ae-bb50-767aba3cc73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 75s 159ms/step - loss: 0.6611 - categorical_accuracy: 0.8416\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99a10863-1fe3-4429-9468-b7164f55e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(model.predict(test_generator), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "038eca6f-5e08-4d2e-81a5-ddd6f4d8a70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[486   1   0   0   0   0   0   0   3   0]\n",
      " [  4 358  44   0   0   0   1   0  62  11]\n",
      " [  0   6 425   0   9   2   0   0  12   6]\n",
      " [  0   0   0 378   1  27  17  15  29   7]\n",
      " [  0   2  16   0 418  15   4   3   6   7]\n",
      " [  0   0   4   8  15 400   2   7   1   0]\n",
      " [ 11   0   0   2   0   9 163   1   8   4]\n",
      " [  0   0   0   9   2  47   0 156   2   0]\n",
      " [ 17   5   6  15   4  10   8   8 312  25]\n",
      " [  5   0   3   1   0   1   6   0  39  65]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_generator.classes,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdcdde09-6a29-403b-ab36-6f4f96d954f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.93      0.99      0.96       490\n",
      "           G       0.96      0.75      0.84       480\n",
      "           H       0.85      0.92      0.89       460\n",
      "           I       0.92      0.80      0.85       474\n",
      "           J       0.93      0.89      0.91       471\n",
      "           K       0.78      0.92      0.84       437\n",
      "           L       0.81      0.82      0.82       198\n",
      "           M       0.82      0.72      0.77       216\n",
      "           N       0.66      0.76      0.71       410\n",
      "           O       0.52      0.54      0.53       120\n",
      "\n",
      "    accuracy                           0.84      3756\n",
      "   macro avg       0.82      0.81      0.81      3756\n",
      "weighted avg       0.85      0.84      0.84      3756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = list(test_generator.class_indices.keys())\n",
    "print(classification_report(test_generator.classes,preds,target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982c8cb2-f5d0-4219-b102-621407351d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                            input_shape=(540, 490, 3)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2),padding = 'same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1000, activation='relu'))\n",
    "    model.add(layers.Dense(200, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7a1bd4-d0a4-42d8-93a0-a378d8bc6437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0828s vs `on_train_batch_end` time: 0.1825s). Check your callbacks.\n",
      "6008/6008 - 1742s - loss: 2.2701 - acc: 0.1257 - val_loss: 2.2293 - val_acc: 0.1305\n",
      "New best accuracy: 0.12571580708026886\n",
      "WARNING:tensorflow:From C:\\Users\\mattl\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\mattl\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0828s vs `on_train_batch_end` time: 0.1856s). Check your callbacks.\n",
      "6008/6008 - 1753s - loss: 2.2670 - acc: 0.1302 - val_loss: 2.2303 - val_acc: 0.1278\n",
      "New best accuracy: 0.13017712533473969\n",
      "INFO:tensorflow:Assets written to: .\\SavedModels\\iterCNN\\assets\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0857s vs `on_train_batch_end` time: 0.1920s). Check your callbacks.\n",
      "6008/6008 - 1735s - loss: 2.2520 - acc: 0.1277 - val_loss: 2.2302 - val_acc: 0.1278\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0868s vs `on_train_batch_end` time: 0.1835s). Check your callbacks.\n",
      "6008/6008 - 1733s - loss: 2.2573 - acc: 0.1234 - val_loss: 2.2306 - val_acc: 0.1305\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0838s vs `on_train_batch_end` time: 0.1835s). Check your callbacks.\n",
      "6008/6008 - 1733s - loss: 2.2527 - acc: 0.1254 - val_loss: 2.2319 - val_acc: 0.1254\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0838s vs `on_train_batch_end` time: 0.1855s). Check your callbacks.\n",
      "6008/6008 - 1737s - loss: 2.2578 - acc: 0.1273 - val_loss: 2.2318 - val_acc: 0.1278\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1925s). Check your callbacks.\n",
      "6008/6008 - 1735s - loss: 2.2591 - acc: 0.1253 - val_loss: 2.2309 - val_acc: 0.1278\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1841s). Check your callbacks.\n",
      "6008/6008 - 1737s - loss: 2.2638 - acc: 0.1261 - val_loss: 2.2305 - val_acc: 0.1260\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0838s vs `on_train_batch_end` time: 0.1855s). Check your callbacks.\n",
      "6008/6008 - 1731s - loss: 2.2577 - acc: 0.1245 - val_loss: 2.2322 - val_acc: 0.1262\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1915s). Check your callbacks.\n",
      "6008/6008 - 1732s - loss: 2.2588 - acc: 0.1236 - val_loss: 2.2301 - val_acc: 0.1278\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0857s vs `on_train_batch_end` time: 0.1825s). Check your callbacks.\n",
      "6008/6008 - 1734s - loss: 2.2551 - acc: 0.1248 - val_loss: 2.2345 - val_acc: 0.1262\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0987s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n",
      "6008/6008 - 1731s - loss: 2.2516 - acc: 0.1232 - val_loss: 2.2322 - val_acc: 0.1262\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0857s vs `on_train_batch_end` time: 0.1825s). Check your callbacks.\n",
      "6008/6008 - 1741s - loss: 2.3049 - acc: 0.1242 - val_loss: 2.2304 - val_acc: 0.1276\n",
      "6008/6008 - 1730s - loss: 2.2640 - acc: 0.1241 - val_loss: 2.2324 - val_acc: 0.1254\n",
      "6008/6008 - 1739s - loss: 2.2580 - acc: 0.1262 - val_loss: 2.2301 - val_acc: 0.1262\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0858s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n",
      "6008/6008 - 1738s - loss: 2.2579 - acc: 0.1271 - val_loss: 2.2365 - val_acc: 0.1278\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n",
      "6008/6008 - 1737s - loss: 2.3018 - acc: 0.1274 - val_loss: 2.2322 - val_acc: 0.1254\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0853s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n",
      "6008/6008 - 1731s - loss: 2.2673 - acc: 0.1256 - val_loss: 2.2315 - val_acc: 0.1305\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0838s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n",
      "6008/6008 - 1737s - loss: 2.2550 - acc: 0.1276 - val_loss: 2.2334 - val_acc: 0.1302\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1835s). Check your callbacks.\n",
      "6008/6008 - 1740s - loss: 2.2531 - acc: 0.1227 - val_loss: 2.2309 - val_acc: 0.1262\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0837s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n",
      "6008/6008 - 1732s - loss: 2.2519 - acc: 0.1266 - val_loss: 2.2292 - val_acc: 0.1305\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0848s vs `on_train_batch_end` time: 0.1850s). Check your callbacks.\n",
      "6008/6008 - 1739s - loss: 2.2555 - acc: 0.1262 - val_loss: 2.2323 - val_acc: 0.1254\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0838s vs `on_train_batch_end` time: 0.1845s). Check your callbacks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-947484640661>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m               metrics=['acc'])\n\u001b[1;32m----> 7\u001b[1;33m     history = model.fit(train_generator,\n\u001b[0m\u001b[0;32m      8\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m30041\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \"\"\"\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    343\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m           \u001b[0mnumpy_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "for i in range(36):\n",
    "    model = instantiate_model()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=.0001),\n",
    "              metrics=['acc'])\n",
    "    history = model.fit(train_generator,\n",
    "                        steps_per_epoch= 30041//batch_size,\n",
    "                        epochs=1,\n",
    "                        validation_data=val_generator,\n",
    "                        validation_steps= 3756//batch_size,\n",
    "                        verbose = 2)\n",
    "    acc = history.history['acc'][-1]\n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        print(f'New best accuracy: {best_acc}')\n",
    "        model.save('.\\SavedModels\\iterCNN', overwrite = True)\n",
    "    del model\n",
    "    del history\n",
    "    tf.keras.backend.clear_session()\n",
    "    for i in range (100):\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf08fa-b36c-4b7c-b64c-c668dde8597f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
